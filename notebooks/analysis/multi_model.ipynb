{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "def compute_metrics(y_pred, y, protection=1e-8):\n",
    "    \"\"\"\n",
    "    Compute accuracy, AUC score, Negative Log Loss, MSE and F1 score\n",
    "    \"\"\"\n",
    "    # print(y_pred.min(), y_pred.max(), y_pred.shape)\n",
    "    y_pred = np.array([i if np.isfinite(i) else 0.5 for i in y_pred])\n",
    "    acc = accuracy_score(y, y_pred >= 0.5)\n",
    "    auc = roc_auc_score(y, y_pred)\n",
    "    return acc, auc\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "    \"\"\"\n",
    "    Keep track of metrics over time in a dictionary.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.metrics = {}\n",
    "        self.counts = {}\n",
    "\n",
    "    def store(self, new_metrics):\n",
    "        for key in new_metrics:\n",
    "            if key in self.metrics:\n",
    "                self.metrics[key] += new_metrics[key]\n",
    "                self.counts[key] += 1\n",
    "            else:\n",
    "                self.metrics[key] = new_metrics[key]\n",
    "                self.counts[key] = 1\n",
    "\n",
    "    def average(self):\n",
    "        average = {k: v / self.counts[k] for k, v in self.metrics.items()}\n",
    "        self.metrics, self.counts = {}, {}\n",
    "        return average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\"elemmath_2021\", \"ednet_kt3\", \"eedi\", \"junyi_15\"]\n",
    "SEED = 888\n",
    "dataset = \"junyi_15\"\n",
    "\n",
    "DATASET_NAMES = {\n",
    "    \"elemmath_2021\": \"ElemMath2021\",\n",
    "    \"ednet_kt3\": \"EdNet KT3\",\n",
    "    \"eedi\": \"Eedi\",\n",
    "    \"junyi_15\": \"Junyi15\"\n",
    "}\n",
    "\n",
    "splits = []\n",
    "for i in range(5):\n",
    "    path = \"./../../data/\" + dataset + \"/preparation/split_s\" + str(SEED) + \"_\" + str(i) + \".pkl\"\n",
    "    with open(path, \"rb\") as file_object:\n",
    "        s = pickle.load(file_object)\n",
    "    splits.append(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine ACC and AUC of multi model evaluation\n",
    "\n",
    "def get_eval(p, dataset, suf, splits, split_id):\n",
    "    path = \"partitioning/\" + dataset + \"_\" + p + \"_s\" + str(split_id) + \"_\" + suf + \".pkl\"\n",
    "    train_selector = splits[split_id][\"selector_train\"]\n",
    "    test_selector = splits[split_id][\"selector_test\"]\n",
    "    \n",
    "    with open(path, 'rb') as f:\n",
    "        res_dict = pickle.load(f)\n",
    "\n",
    "    y_pred_tr = res_dict[\"y_pred_train\"][train_selector]\n",
    "    y_truth_tr = res_dict[\"y_truth_train\"][train_selector]\n",
    "    y_pred_te = res_dict[\"y_pred_test\"][test_selector]\n",
    "    y_truth_te = res_dict[\"y_truth_teest\"][test_selector]\n",
    "\n",
    "    acc_train, auc_train = \\\n",
    "            compute_metrics(y_pred_tr, y_truth_tr)\n",
    "\n",
    "    acc_test, auc_test = \\\n",
    "        compute_metrics(y_pred_te, y_truth_te)\n",
    "\n",
    "    return acc_train, auc_train, acc_test, auc_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb_lr_performance(ps, dataset, suf, splits, split_id):\n",
    "    \n",
    "    # combine predictions\n",
    "    train_selector = splits[split_id][\"selector_train\"]\n",
    "    test_selector = splits[split_id][\"selector_test\"]\n",
    "\n",
    "    pred_tr, pred_te = [], []\n",
    "    for p in ps:\n",
    "        print(p)\n",
    "        path = \"partitioning/\" + dataset + \"_\" + p + \"_s\" + str(split_id) + \"_\" + suf + \".pkl\"\n",
    "        with open(path, 'rb') as f:\n",
    "            res_dict = pickle.load(f)\n",
    "\n",
    "        y_pred_tr = res_dict[\"y_pred_train\"][train_selector]\n",
    "        y_truth_tr = res_dict[\"y_truth_train\"][train_selector]\n",
    "        y_pred_te = res_dict[\"y_pred_test\"][test_selector]\n",
    "        y_truth_te = res_dict[\"y_truth_teest\"][test_selector]\n",
    "        \n",
    "        pred_tr.append(y_pred_tr) \n",
    "        pred_te.append(y_pred_te)\n",
    "\n",
    "    X_train = np.array(pred_tr).T\n",
    "    y_train = y_truth_tr\n",
    "    X_test = np.array(pred_te).T\n",
    "    y_test = y_truth_te\n",
    "\n",
    "    lr_model = LogisticRegression(solver=\"liblinear\",\n",
    "                            max_iter=5000,\n",
    "                            n_jobs=8,\n",
    "                            verbose=1)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    pred_tr = lr_model.predict_proba(X_train)[:, 1]\n",
    "    pred_te = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc_train, auc_train = \\\n",
    "        compute_metrics(pred_tr, y_train)\n",
    "    acc_test, auc_test = \\\n",
    "        compute_metrics(pred_te, y_test)\n",
    "\n",
    "    return acc_train, auc_train, acc_test, auc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual split performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Best-LR\n",
    "suf = \"i_s_scA_scW_tcA_tcW\"\n",
    "# elemmath_2021\n",
    "# partitions = [\"single\", \"time\", \"i\", \"s\", \"sm\", \"tea\", \"sch\", \"c\", \"t\", \"at\"]\n",
    "# ednet\n",
    "# partitions = [\"single\", \"time\", \"i\", \"hashed_skill_id\", \"sm\", \"bundle_id\", \"part_id\", \"at\"]\n",
    "# eedi\n",
    "# [\"single\", \"time\", \"i\", \"hashed_skill_id\", \"sm\", \"tea\", \"bundle_id\"]\n",
    "# junyi\n",
    "partitions = [\"single\", \"time\", \"i\", \"s\", \"sm\", \"part_id\"]\n",
    "\n",
    "\n",
    "### AugmentedLR\n",
    "# elemmath_2021\n",
    "# suf = \"i_icA_TW_icW_TW_lag_time_cat_n_gram_postcA_postcW_ppe_precA_precW_\" \\\n",
    "#     + \"prev_resp_time_cat_rc_rpfa_F_rpfa_R_s_scA_TW_scW_TW_sm_t_tcA_TW_\" \\\n",
    "#     + \"tcW_TW_user_avg_correct_vw\"\n",
    "# ednet\n",
    "# suf = \"i_icA_TW_icW_TW_lag_time_cat_n_gram_partcA_partcW_ppe_\" \\\n",
    "#     + \"prev_resp_time_cat_rpfa_F_rpfa_R_s_scA_TW_scW_TW_sm_tcA_TW_tcW_TW_\" \\\n",
    "#     + \"user_avg_correct_vs_vw\"\n",
    "# partitions = [\"single\", \"time\", \"i\", \"hashed_skill_id\", \"sm\", \"bundle_id\", \"part_id\", \"at\"]\n",
    "# eedi\n",
    "# suf = \"bundle_i_icA_TW_icW_TW_n_gram_ppe_precA_precW_rpfa_F_rpfa_R_s_\" + \\\n",
    "#     \"scA_TW_scW_TW_sm_tcA_TW_tcW_TW_tea_user_avg_correct\"\n",
    "# partitions = [\"single\", \"time\", \"i\", \"hashed_skill_id\", \"sm\", \"tea\", \"bundle_id\"]\n",
    "# junyi\n",
    "suf = \"hour_i_icA_TW_icW_TW_lag_time_cat_n_gram_postcA_postcW_ppe_precA_\" \\\n",
    "    + \"precW_prev_resp_time_cat_rc_rpfa_F_rpfa_R_rt_s_scA_TW_scW_TW_sm_tcA_TW_\" \\\n",
    "    + \"tcW_TW_user_avg_correct\"\n",
    "partitions = [\"single\", \"time\", \"i\", \"s\", \"sm\", \"part_id\"]\n",
    "\n",
    "print(dataset)\n",
    "for p in partitions:\n",
    "    print(\"Partition: \" + p)\n",
    "    print(\"\")\n",
    "    acc_vals, auc_vals = [], []\n",
    "    for split_id in range(5):\n",
    "        print(\"Split\", split_id)\n",
    "        acc_train, auc_train, acc_test, auc_test = \\\n",
    "            get_eval(p, dataset, suf, splits, split_id)\n",
    "        acc_vals.append(acc_test)\n",
    "        auc_vals.append(auc_test)\n",
    "\n",
    "    acc_vals = np.array(acc_vals)\n",
    "    auc_vals = np.array(auc_vals)\n",
    "    print(acc_vals)\n",
    "    print(auc_vals)\n",
    "\n",
    "    acc_avg = np.round(np.mean(acc_vals), decimals=6)\n",
    "    acc_std = np.round(np.std(acc_vals), decimals=6)\n",
    "    auc_avg = np.round(np.mean(auc_vals), decimals=6)\n",
    "    auc_std = np.round(np.std(auc_vals), decimals=6)\n",
    "\n",
    "    out = \"\\\\avgvar{\" + str(acc_avg) + \"}{\" + str(acc_std) + \"} &\"\n",
    "    out += \" \\\\avgvar{\" + str(auc_avg) + \"}{\" + str(auc_std) + \"} \\n\\n\"\n",
    "    print(out)\n",
    "\n",
    "    print(\"\\n---------------------------------------\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher LR performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Best-LR\n",
    "suf = \"i_s_scA_scW_tcA_tcW\"\n",
    "# elemmath_2021\n",
    "ps = ['s', 'sm', 'c', 'at']\n",
    "# ednet\n",
    "# ps = ['single', 'time', 'hashed_skill_id', 'sm', 'bundle_id', 'at'] \n",
    "# eedi\n",
    "# ps = ['time', 'i', 'bundle_id']\n",
    "# junyi_15\n",
    "# ps = ['single', 'time', 'i', 'sm', 'part_id']\n",
    "\n",
    "# AugmentedLR\n",
    "# elemmath_2021 \n",
    "# suf = \"i_icA_TW_icW_TW_lag_time_cat_n_gram_postcA_postcW_ppe_precA_precW_\" \\\n",
    "#     + \"prev_resp_time_cat_rc_rpfa_F_rpfa_R_s_scA_TW_scW_TW_sm_t_tcA_TW_\" \\\n",
    "#     + \"tcW_TW_user_avg_correct_vw\"\n",
    "# ps = [\"sm\", \"c\"]\n",
    "# ednet\n",
    "# suf = \"i_icA_TW_icW_TW_lag_time_cat_n_gram_partcA_partcW_ppe_\" \\\n",
    "#     + \"prev_resp_time_cat_rpfa_F_rpfa_R_s_scA_TW_scW_TW_sm_tcA_TW_tcW_TW_\" \\\n",
    "#     + \"user_avg_correct_vs_vw\"\n",
    "# ps = ['time', 'sm']\n",
    "# eedi\n",
    "# suf = \"bundle_i_icA_TW_icW_TW_n_gram_ppe_precA_precW_rpfa_F_rpfa_R_s_\" + \\\n",
    "#     \"scA_TW_scW_TW_sm_tcA_TW_tcW_TW_tea_user_avg_correct\"\n",
    "# ps = ['time', 'sm']\n",
    "# junyi\n",
    "suf = \"hour_i_icA_TW_icW_TW_lag_time_cat_n_gram_postcA_postcW_ppe_precA_\" \\\n",
    "    + \"precW_prev_resp_time_cat_rc_rpfa_F_rpfa_R_rt_s_scA_TW_scW_TW_sm_tcA_TW_\" \\\n",
    "    + \"tcW_TW_user_avg_correct\"\n",
    "ps = ['time', 'sm']\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "print(\"-----------------------------\")\n",
    "acc_vals, auc_vals = [], []\n",
    "for split_id in range(5):\n",
    "    print(\"Split\", split_id)\n",
    "    acc_train, auc_train, acc_test, auc_test = \\\n",
    "        comb_lr_performance(ps, dataset, suf, splits, split_id)\n",
    "    acc_vals.append(acc_test)\n",
    "    auc_vals.append(auc_test)\n",
    "\n",
    "acc_vals = np.array(acc_vals)\n",
    "auc_vals = np.array(auc_vals)\n",
    "print(acc_vals)\n",
    "print(auc_vals)\n",
    "\n",
    "acc_avg = np.round(np.mean(acc_vals), decimals=6)\n",
    "acc_std = np.round(np.std(acc_vals), decimals=6)\n",
    "auc_avg = np.round(np.mean(auc_vals), decimals=6)\n",
    "auc_std = np.round(np.std(auc_vals), decimals=6)\n",
    "\n",
    "print(\"\\n---------------------------------------\\n\")\n",
    "\n",
    "out = \"\\\\avgvar{\" + str(acc_avg) + \"}{\" + str(acc_std) + \"} &\"\n",
    "out += \" \\\\avgvar{\" + str(auc_avg) + \"}{\" + str(auc_std) + \"} \\n\\n\"\n",
    "\n",
    "print(ps)\n",
    "print(\"\\n---------------------------------------\\n\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5de9c6bbfc24e23fab00c3f9f8dc98e9bcec0a8369077ced4c7728b8be480d9b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('vedu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
